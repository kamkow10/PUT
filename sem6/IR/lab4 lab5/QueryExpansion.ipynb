{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "0) Just some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import common as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1) Simple search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.1) Get acquainted with the below class. There are several TODOs. However, DO NOT complete them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaai', 'about', 'academic', 'access', 'acquired', 'acquisition', 'action', 'activity', 'actual', 'adaptive', 'add', 'advance', 'agricultural', 'aha', 'aim', 'alert', 'algorithm', 'all', 'analysis', 'and', 'announcement', 'answer', 'anyone', 'application', 'applied', 'apply', 'applying', 'approach', 'approache', 'april', 'archive', 'are', 'area', 'areas', 'article', 'artificial', 'asked', 'august', 'author', 'automated', 'automatically', 'autonomous', 'available', 'awards', 'backend', 'backgammon', 'baldi', 'based', 'basic', 'bayesian']\n"
     ]
    }
   ],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self):\n",
    "        ### keeps unique terms (SORTED!)\n",
    "        self.terms = self.loadTerms(\"terms.txt\")\n",
    "        self.idfs = [] ### IDF coefficients\n",
    "        self.corM = [] ### a correlation matrix\n",
    "\n",
    "    ### load terms\n",
    "    def loadTerms(self, fileName):\n",
    "        file = open(fileName,'r', encoding='utf-8-sig')\n",
    "        k = [self.proc(s) for s in file.readlines()]\n",
    "        k.sort()\n",
    "        return k\n",
    "\n",
    "    ### ignore it\n",
    "    def proc(self, s):\n",
    "        if s[-1] == '\\n': return s[:-1]\n",
    "        else: return s\n",
    "    \n",
    "    ### TODO (DO NOT FINISH THIS METHOD YET. YOU WILL BE ASKED FOR IT LATER) \n",
    "    def computeIDFs(self, documents):\n",
    "        inDocList = []\n",
    "        for term in self.terms:\n",
    "            inDoc = 0\n",
    "            for document in documents:\n",
    "                for docTerm in document.tokens:\n",
    "                    if term == docTerm:\n",
    "                        inDoc += 1\n",
    "                        break\n",
    "            inDocList.append(inDoc)\n",
    "        self.idfs = [math.log((len(documents)/x), len(documents)) for x in inDocList]\n",
    "    \n",
    "    ### TODO (DO NOT FINISH THIS METHOD YET. YOU WILL BE ASKED FOR IT LATER) \n",
    "    def computeCorM(self, documents):\n",
    "        for i in range(len(self.terms)):\n",
    "            any = 0\n",
    "            tab = []\n",
    "            for j in range(len(documents)):\n",
    "                tab.append(0);\n",
    "                tab[j] = len([term for term in documents[j].tokens if term == self.terms[i]])\n",
    "            self.corM.append(tab)\n",
    "        for i in range(len(self.corM)):\n",
    "            sum = 0\n",
    "            for j in range(len(self.corM[i])):\n",
    "                sum += math.pow(self.corM[i][j], 2)\n",
    "            sum = math.sqrt(sum)\n",
    "            for j in range(len(self.corM[i])):\n",
    "                self.corM[i][j] /= sum\n",
    "        transM = np.transpose(self.corM)\n",
    "        self.corM = np.matmul(self.corM, transM)\n",
    "        for i in range(len(self.corM)):\n",
    "            self.corM[i][i] = -1;\n",
    "        \n",
    "\n",
    "### SOME DEBUG\n",
    "dictionary = Dictionary()\n",
    "print(dictionary.terms[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.2) Load files: here we load some example collection of documents. RAW_DOCUMENTS = just strings. Check if the documents are loaded correctly (e.g., print RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David W. Aha:  Machine Learning Page\n",
      " Machine Learning Resources. Suggestions welcome. ... (WizRule); ZDM Scientific\n",
      " Ltd. Conference Announcements. Courses on Machine Learning. Data Repositories. ... \n",
      " Description: Comprehensive machine learning resources from Applications to Tutorials.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RAW_DOCUMENTS = cm.loadDocuments(\"documents.txt\")\n",
    "### SOME DEBUG\n",
    "print(RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'aha', 'machine', 'learning', 'page', 'machine', 'learning', 'resource', 'suggestion', 'welcome', 'wizrule', 'zdm', 'scientific', 'ltd', 'conference', 'announcement', 'course', 'machine', 'learning', 'data', 'repository', 'description', 'comprehensive', 'machine', 'learning', 'resource', 'from', 'application', 'tutorials']\n"
     ]
    }
   ],
   "source": [
    "### SOME DEBUG, JUST RUN; check if (a) common.py is imported correctly and (b) \n",
    "### tokens are correctly derived from some document (e.g., RAW_DOCUMENTS[0])\n",
    "print(cm.simpleTextProcessing(RAW_DOCUMENTS[0], re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.3) Get acquainted with the below class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class Document:\n",
    "    def __init__(self, doc_id, raw_document, dictionary):\n",
    "        self.doc_id = doc_id ### DOC ID, simply 0,1,2,3....\n",
    "        self.raw_document = raw_document ### raw data, i.e., string data\n",
    "        self.dictionary = dictionary # reference to the dictionary\n",
    "        \n",
    "        ### DOCUMENT REPRESENTATIONS\n",
    "        self.tokens = cm.simpleTextProcessing(raw_document, re) ### get terms\n",
    "        self.bow = [] # Bag Of Words (BOW - number of term occurences)\n",
    "        self.tf = [] # TF representation\n",
    "        self.tf_idf = [] # TF-IDF representation\n",
    "\n",
    "    ### TODO - complete this method; it should compute a BOW representation\n",
    "    def computeBOW_Representation(self):\n",
    "        for term in self.tokens:\n",
    "            count = 0\n",
    "            for term2 in self.tokens:\n",
    "                if term == term2:\n",
    "                    count += 1\n",
    "            self.bow.append(count)\n",
    "    \n",
    "    ### TODO - complete this method; it should compute a TF representation\n",
    "    def computeTF_Representation(self):\n",
    "        self.tf = [(count/max(self.bow)) for count in self.bow]\n",
    "    \n",
    "    ### TODO - complete this method; it should compute a TFxIDF representation \n",
    "    ### (important: it should not be run before dictionary.idfs are not computed!)\n",
    "    def computeTF_IDF_Representation(self):\n",
    "        for i in range(len(self.tf)):\n",
    "            for j in range(len(self.dictionary.terms)):\n",
    "                if self.dictionary.terms[j] == self.tokens[i]:\n",
    "                    self.tf_idf.append(self.tf[i] * self.dictionary.idfs[j])\n",
    "                    \n",
    "            \n",
    "    \n",
    "    def computeRepresentations(self):\n",
    "        self.computeBOW_Representation()\n",
    "        self.computeTF_Representation()\n",
    "        self.computeTF_IDF_Representation()\n",
    "    \n",
    "documents = [Document(i, RAW_DOCUMENTS[i], dictionary) for i in range(len(RAW_DOCUMENTS))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.4) Compute IDFs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['working', 1.0], ['www', 1.0], ['york', 1.0], ['young', 1.0], ['zdm', 1.0]]\n",
      "[['learning', 0.005134641233681233], ['machine', 0.005134641233681233], ['the', 0.10094954712397083], ['and', 0.16520249131202333], ['description', 0.19963159196149574]]\n"
     ]
    }
   ],
   "source": [
    "### TODO COMPUTE IDFS HERE (FINISH THE PROPER METHOD OF THE DICTIONARY CLASS - DO NOT FORGET TO RE-RUN THE CELL)\n",
    "dictionary.computeIDFs(documents)\n",
    "\n",
    "### SOME DEBUG\n",
    "res = [[dictionary.terms[i], dictionary.idfs[i]] for i in range(len(dictionary.terms))]\n",
    "res.sort(key = lambda x: x[1])\n",
    "# LEAST COMMON WORDS - HIGH IDF\n",
    "print(res[-5:])\n",
    "# MOST COMMON WORDS - LOW IDF\n",
    "print(res[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.5) Compute the document representations (for each document run computeRepresentations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 4, 4, 1, 4, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 4, 4, 2, 1, 1, 1]\n",
      "\n",
      "\n",
      "[0.25, 0.25, 1.0, 1.0, 0.25, 1.0, 1.0, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 1.0, 1.0, 0.25, 0.25, 0.25, 0.25, 1.0, 1.0, 0.5, 0.25, 0.25, 0.25]\n",
      "\n",
      "\n",
      "[0.1725938086321159, 0.1725938086321159, 0.005134641233681233, 0.005134641233681233, 0.0774061913678841, 0.005134641233681233, 0.005134641233681233, 0.24286219817679816, 0.25, 0.1725938086321159, 0.25, 0.25, 0.25, 0.25, 0.1112508533112449, 0.2112969043160579, 0.1725938086321159, 0.005134641233681233, 0.005134641233681233, 0.1112508533112449, 0.188657044679129, 0.049907897990373935, 0.2112969043160579, 0.005134641233681233, 0.005134641233681233, 0.24286219817679816, 0.13389071294817384, 0.14134667383281885, 0.188657044679129]\n"
     ]
    }
   ],
   "source": [
    "for d in documents: d.computeRepresentations()\n",
    "### SOME DEBUG (you should see some 4s - which terms are these?)\n",
    "print(documents[0].bow)\n",
    "print('\\n')\n",
    "print(documents[0].tf)\n",
    "print('\\n')\n",
    "print(documents[0].tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.6) Finish the below method. It should compute and return a cosine similarity (v1 and v2 are two vectors - tf-idf representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "### TODO \n",
    "def getSimilarity(v1, v2):\n",
    "    return (sum([a * b for a, b in zip(v1,v2)]))/(math.sqrt(sum([math.pow(a, 2) for a in v1]) * sum([math.pow(b, 2) for b in v2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.7) Run the below script for different queries. getTopResults seeks for documents being the most similar/relevant to the query. Do you find the results satisfactory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# query = \"machine learning\"\n",
    "#query = \"academic research\"\n",
    "#query = \"international conference\"\n",
    "query = \"international conference washington\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK = 1 WITH SIMILARITY = 0.6646561196491053 | DOC ID = 39\n",
      "ICML2002 - Sydney\n",
      " The Nineteenth International Conference on Machine Learning (ICML-2002). ... Previous\n",
      " meetings on machine learning: ICML-2001, ICML-2000, ICML-99 , ICML-98. ... \n",
      "\n",
      "\n",
      "RANK = 2 WITH SIMILARITY = 0.5739996933025575 | DOC ID = 76\n",
      "ICML 2003\n",
      " The Twentieth International Conference on Machine Learning (ICML-2003).\n",
      " August 21-24, 2003 Washington, DC USA. The Twentieth International ... \n",
      "\n",
      "\n",
      "RANK = 3 WITH SIMILARITY = 0.5448792733955077 | DOC ID = 31\n",
      "New Link To Robert Holte's home page for Machine Learning\n",
      " New Link To Robert Holte's home page for Machine Learning. The web\n",
      " pages maintained by Robert Holte for Machine Learning have moved. ... \n",
      "\n",
      "\n",
      "RANK = 4 WITH SIMILARITY = 0.5249037627063615 | DOC ID = 10\n",
      "Kluwer\n",
      " Kluwer Alert, Subscribe today for our free electronic notification service\n",
      " for journal tables of contents and new product announcements ... \n",
      "\n",
      "\n",
      "RANK = 5 WITH SIMILARITY = 0.49783648821996174 | DOC ID = 74\n",
      "ECML/PKDD-2002\n",
      " ... Photos Proposals 2003 Sitemap Home ECML/PKDD-2002. 13th European Conference\n",
      " on Machine Learning (ECML'02). 6th European Conference on ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getTopResults(query, documents, dictionary, similarity, top = 5):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    ranks = [[d, getSimilarity(d.tf_idf, qd.tf_idf)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults(query, documents, dictionary, getSimilarity, top = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2) Query expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1) Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.1.1) Finish dictionary.computeCorM method (see class Dictionary). It should generate a correlation matrix (correlation between terms).\n",
    "\n",
    "IMPORTANT: although corM[ i ][ i ] (for each i) should be 1.0, set it to -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.         -1.          0.         ...  0.18898224  0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -1.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.18898224  0.         ... -1.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.         -1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "  -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "### TODO - COMPLETE THE computeCorM METHOD (see one of the first cells)\n",
    "dictionary.computeCorM(documents)\n",
    "print(dictionary.corM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.1.2) Finish the below method. For each term in the query (you must parse the query, see getTopResults() method), find another term which is the most correlated with the input term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n"
     ]
    }
   ],
   "source": [
    "# query = \"machine\"\n",
    "# query = \"algorithm\"\n",
    "# query = \"learning\"\n",
    "# query = \"conference\"\n",
    "query = \"research\"\n",
    "# query = \"concept\"\n",
    "\n",
    "def suggestKeywords(query, dictionary):\n",
    "    ### TODO\n",
    "    result = \"\"\n",
    "    for i in range(len(dictionary.terms)):\n",
    "        if query == dictionary.terms[i]:\n",
    "            maxInd = 0\n",
    "            for j in range(len(dictionary.corM[i])):\n",
    "                if dictionary.corM[i][j] > dictionary.corM[i][maxInd]: maxInd = j\n",
    "            result = dictionary.terms[maxInd]\n",
    "            break;\n",
    "    print(result)\n",
    "    pass\n",
    "        \n",
    "suggestKeywords(query, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.2) Rocchio algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "$\\overrightarrow{q_{m}} = \\alpha \\overrightarrow{q} + \\left(\\beta \\cdot \\dfrac{1}{|D_{r}|} \\sum_{\\overrightarrow{D_j} \\in D_{r}} \\overrightarrow{D_j} \\right) - \\left(\\gamma \\cdot \\dfrac{1}{|D_{nr}|} \\sum_{\\overrightarrow{D_j} \\in D_{nr}} \\overrightarrow{D_j} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.2.1) Firstly, run the below code. Observe the results. Assume that we do not like the first and the second result (Docs 63 and 77). However, assume that docs 29 and 36 are satisfactory. Now, modfify the method. It should alter the query vector, according to Rocchio algorithm. Check the result for the above considered scenario (relevant docs = 29 and 36; not relevant = 63 and 77). Check the results for different values of alpha, beta, and gamma coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine\n",
      "learning\n",
      "machine\n",
      "learning\n",
      "machine\n",
      "learning\n",
      "machine\n",
      "learning\n",
      "\n",
      "\n",
      "RANK = 1 WITH SIMILARITY = 0.7256420167563681 | DOC ID = 45\n",
      "University of York Machine Learning Group\n",
      " Content Introduction. \n",
      "\n",
      "\n",
      "RANK = 2 WITH SIMILARITY = 0.5587348552355521 | DOC ID = 10\n",
      "Kluwer\n",
      " Kluwer Alert, Subscribe today for our free electronic notification service\n",
      " for journal tables of contents and new product announcements ... \n",
      "\n",
      "\n",
      "RANK = 3 WITH SIMILARITY = 0.5292518458228739 | DOC ID = 62\n",
      "Open Directory - Computers: Artificial Intelligence: Machine ... \n",
      " ... David W. Aha: Machine Learning Page - Comprehensive machine learning\n",
      " resources from Applications to Tutorials. Machine Learning ... \n",
      "\n",
      "\n",
      "RANK = 4 WITH SIMILARITY = 0.5050922063815935 | DOC ID = 82\n",
      "IJCAI 99 Workshop: Machine Learning for Information Filtering. Workshop\n",
      " on \"Machine Learning for Information Filtering\" at IJCAI 99. ... \n",
      "\n",
      "\n",
      "RANK = 5 WITH SIMILARITY = 0.4771068564123384 | DOC ID = 32\n",
      "IFIP WG 12.2 Global Web Site for Machine Learning and Case-Based ... \n",
      " IFIP WG 12.2 Global Web Site for Machine Learning and Case-Based Reasoning\n",
      " Researchers. You can search for Machine Learning and Case ... \n",
      "\n",
      "\n",
      "RANK = 6 WITH SIMILARITY = 0.47593204060406596 | DOC ID = 71\n",
      "Cogprints - Subject: Machine Learning\n",
      " Subject: Machine Learning. ... Proceedings AAAI Fall Symposium on Machine Learning and\n",
      " Computer Vision, pages 70-74, Research Triangle Park, North Carolina, USA. ... \n",
      "\n",
      "\n",
      "RANK = 7 WITH SIMILARITY = 0.44213813906046767 | DOC ID = 24\n",
      "Yahoo! Science > Computer Science > Artificial Intelligence > ... \n",
      " ... Knowledge Sharing Effort, The; Machine Learning and Case-Based Reasoning\n",
      " Home Pages; Machine Learning and Inference at GMU; Machine ... \n",
      "\n",
      "\n",
      "RANK = 8 WITH SIMILARITY = 0.43807319609981515 | DOC ID = 33\n",
      "BYU Neural Networks and Machine Learning Lab\n",
      " BYU Neural Networks and Machine Learning Laboratory. Lab Director - Tony\n",
      " Martinez. ... Links to other Neural Network and Machine Learning resources. ... \n",
      "\n",
      "\n",
      "RANK = 9 WITH SIMILARITY = 0.41425494265400953 | DOC ID = 4\n",
      "MLnet OiS - Find information and resources on Machine Learning, ... \n",
      " The Machine Learning Network Online Information Service provides information\n",
      " and resources related to machine learning, knowledge discovery, case-based ... \n",
      " Description: The MLnet OiS offers software, datasets, information about events, research groups, persons and other...\n",
      "\n",
      "\n",
      "RANK = 10 WITH SIMILARITY = 0.4100860567093976 | DOC ID = 86\n",
      "International Conferences on Machine Learning and Applications\n",
      " The 2002 International Conferences on Machine Learning and Applications The\n",
      " 2003 International Conferences on Machine Learning and Applications. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getTopResults_Rocchio(query, \n",
    "                          documents, \n",
    "                          dictionary, \n",
    "                          similarity, \n",
    "                          rel_docs = [29, 36],\n",
    "                          nrel_docs = [63, 77],\n",
    "                          alpha = 0,\n",
    "                          beta = 0.8,\n",
    "                          gamma = 0.2,\n",
    "                          top = 10):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    ##### TODO: MODIFY qd.tf_idf HERE\n",
    "    rels = []\n",
    "    for rel in rel_docs:\n",
    "        tab = []\n",
    "        for word in qd.tokens:\n",
    "            print(word)\n",
    "            relDoc = [document for document in documents if document.doc_id == rel][0]\n",
    "            relQuery = [relDoc.tf_idf[i] for i in range(len(relDoc.tf_idf)) if (relDoc.tokens[i] == word)]\n",
    "            value = 0 if len(relQuery) == 0 else relQuery[0]\n",
    "            tab.append(value)\n",
    "        rels.append(tab)\n",
    "        \n",
    "    nrels = []\n",
    "    for rel in nrel_docs:\n",
    "        tab = []\n",
    "        for word in qd.tokens:\n",
    "            print(word)\n",
    "            relDoc = [document for document in documents if document.doc_id == rel][0]\n",
    "            relQuery = [relDoc.tf_idf[i] for i in range(len(relDoc.tf_idf)) if (relDoc.tokens[i] == word)]\n",
    "            value = 0 if len(relQuery) == 0 else relQuery[0]\n",
    "            tab.append(value)\n",
    "        nrels.append(tab)\n",
    "    relDocValue = [beta * (value/len(rels)) for value in np.sum(rels, axis=0)]\n",
    "    nrelDocValue = [gamma * (value/len(nrels)) for value in np.sum(nrels, axis=0)]\n",
    "    basicValue = [elem * alpha for elem in qd.tf_idf]\n",
    "    qd.tf_idf = [basicValue[i] + relDocValue[i] - nrelDocValue[i] for i in range(len(basicValue))]\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    #####\n",
    "    ranks = [[d, getSimilarity(d.tf_idf, qd.tf_idf)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults_Rocchio(\"machine learning\", documents, dictionary, getSimilarity, top = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.3) WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.3.1) Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<!-- http://www.nltk.org/install.html -->\n",
    "\n",
    "\n",
    "import nltk \n",
    "\n",
    "nltk.download()\n",
    "\n",
    "<!-- https://www.nltk.org/data.html -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Definition: synset = (from wiki) (information science) A set of one or more synonyms that are interchangeable in some context without changing the truth value of the proposition in which they are embedded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.3.2) Display sysents for \"machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('machine.n.01'),\n",
       " Synset('machine.n.02'),\n",
       " Synset('machine.n.03'),\n",
       " Synset('machine.n.04'),\n",
       " Synset('machine.n.05'),\n",
       " Synset('car.n.01'),\n",
       " Synset('machine.v.01'),\n",
       " Synset('machine.v.02')]"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.3.3) Display all definitions (.definition()) for synsets (machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  any mechanical or electrical device that transmits or modifies energy to perform or assist in the performance of human tasks\n",
      "\n",
      "*  an efficient person\n",
      "\n",
      "*  an intricate organization that accomplishes its goals efficiently\n",
      "\n",
      "*  a device for overcoming resistance at one point by applying force at some other point\n",
      "\n",
      "*  a group that controls the activities of a political party\n",
      "\n",
      "*  a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "\n",
      "*  turn, shape, mold, or otherwise finish by machinery\n",
      "\n",
      "*  make by machinery\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "for synset in wn.synsets('machine'):\n",
    "    print(\"* \", synset.definition())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.3.4) For each synset (machine), display its hypernym (a word with a broad meaning constituting a category into which words with more specific meanings fall; a superordinate. For example, colour is a hypernym of red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  [Synset('device.n.01')]\n",
      "\n",
      "*  [Synset('person.n.01')]\n",
      "\n",
      "*  [Synset('organization.n.01')]\n",
      "\n",
      "*  [Synset('mechanical_device.n.01')]\n",
      "\n",
      "*  [Synset('organization.n.01')]\n",
      "\n",
      "*  [Synset('motor_vehicle.n.01')]\n",
      "\n",
      "*  [Synset('shape.v.02')]\n",
      "\n",
      "*  [Synset('produce.v.02')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "for synset in wn.synsets('machine'):\n",
    "    print(\"* \", synset.hypernyms())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See: http://www.nltk.org/howto/wordnet.html\n",
    "for more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co≈õtam\n"
     ]
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}